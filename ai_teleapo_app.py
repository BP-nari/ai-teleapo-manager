import streamlit as st
import pandas as pd
import re
from datetime import datetime, timedelta
import hashlib
import json
import os
from pathlib import Path
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIãƒ†ãƒ¬ã‚¢ãƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .job-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'jobs' not in st.session_state:
    st.session_state.jobs = []
if 'current_job' not in st.session_state:
    st.session_state.current_job = None

class AITeleapoManager:
    def __init__(self):
        self.base_dir = Path("teleapo_jobs")
        self.base_dir.mkdir(exist_ok=True)
        
    def generate_job_id(self):
        """ã‚¸ãƒ§ãƒ–IDã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
        random_suffix = hashlib.md5(str(time.time()).encode()).hexdigest()[:5].upper()
        return f"{timestamp}_{random_suffix}"
    
    def normalize_phone(self, phone_str):
        """é›»è©±ç•ªå·ã‚’æ­£è¦åŒ–ï¼ˆ+81å½¢å¼ã‚’0å§‹ã¾ã‚Šã«å¤‰æ›ï¼‰"""
        if pd.isna(phone_str):
            return ""
        phone_str = str(phone_str).replace("+81", "0").replace(" ", "").replace("-", "")
        return re.sub(r'\D', '', phone_str)
    
    def normalize_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–"""
        if pd.isna(text):
            return ""
        return str(text).strip().lower()
    
    def create_row_key(self, company, phone):
        """è¡ŒæŒ‡ç´‹ã‚’ä½œæˆï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰"""
        # ç¤¾åã‚’æ­£è¦åŒ–ã—ã¦ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
        normalized_company = self.normalize_text(company)
        normalized_phone = self.normalize_phone(phone)
        base = f"{normalized_company}|{normalized_phone}"
        return hashlib.sha256(base.encode('utf-8')).hexdigest()[:16]
    
    def process_filemaker_data(self, df, job_id, output_filename):
        """FileMakerãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        job_dir = self.base_dir / job_id
        job_dir.mkdir(exist_ok=True)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        original_path = job_dir / "fm_export.xlsx"
        df.to_excel(original_path, index=False)
        
        # AIãƒ†ãƒ¬ã‚¢ãƒç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›
        upload_df = df.copy()
        if 'é¡§å®¢å' in upload_df.columns:
            upload_df = upload_df.rename(columns={'é¡§å®¢å': 'ç¤¾å'})
        
        # å¿…è¦ãªåˆ—ã®ã¿æŠ½å‡ºï¼ˆAIãƒ†ãƒ¬ã‚¢ãƒç”¨ï¼‰
        required_columns = ['ç¤¾å', 'é›»è©±ç•ªå·', 'ä½æ‰€çµ±åˆ']
        available_columns = [col for col in required_columns if col in upload_df.columns]
        
        if available_columns:
            upload_df = upload_df[available_columns].copy()
        
        # è¡ŒæŒ‡ç´‹ã‚’ä½œæˆã—ã¦rowmapã‚’ç”Ÿæˆï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰
        rowmap_data = []
        for idx, row in df.iterrows():
            company = row.get('é¡§å®¢å', '') if 'é¡§å®¢å' in df.columns else row.get('ç¤¾å', '')
            phone = row.get('é›»è©±ç•ªå·', '')
            row_key = self.create_row_key(company, phone)
            
            rowmap_data.append({
                'row_key': row_key,
                'company': company,
                'company_normalized': self.normalize_text(company),
                'phone': phone,
                'fm_id': row.get('IDã®é ­ã«ID', ''),
                'index_in_fm': idx
            })
        
        rowmap_df = pd.DataFrame(rowmap_data)
        rowmap_path = job_dir / "rowmap.csv"
        rowmap_df.to_csv(rowmap_path, index=False)
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨CSVã‚’ä¿å­˜ï¼ˆUTF-8 with BOMï¼‰
        upload_path = job_dir / f"{output_filename}.csv"
        try:
            # ã¾ãšShift-JISã‚’è©¦ã™
            upload_df.to_csv(upload_path, index=False, encoding='shift_jis')
        except UnicodeEncodeError:
            # Shift-JISã§ä¿å­˜ã§ããªã„å ´åˆã¯UTF-8 with BOMã‚’ä½¿ç”¨
            upload_df.to_csv(upload_path, index=False, encoding='utf-8-sig')
        
        # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ä½œæˆ
        manifest = {
            'job_id': job_id,
            'created_at': datetime.now().isoformat(),
            'original_filename': output_filename,
            'total_rows': len(df),
            'files': {
                'fm_export': 'fm_export.xlsx',
                'upload': f'{output_filename}.csv',
                'rowmap': 'rowmap.csv'
            }
        }
        
        manifest_path = job_dir / "manifest.json"
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, ensure_ascii=False, indent=2)
        
        return {
            'job_id': job_id,
            'upload_path': upload_path,
            'total_rows': len(df),
            'manifest': manifest
        }
    
    def analyze_call_results(self, df):
        """é€šè©±çµæœã‚’åˆ†æ"""
        # é›»è©±ç•ªå·ã‚’æ­£è¦åŒ–
        df["é›»è©±ç•ªå·"] = df["é›»è©±ç•ªå·"].astype(str).str.replace(r'^\+81\s*', '0', regex=True)
        df["é›»è©±ç•ªå·"] = df["é›»è©±ç•ªå·"].str.replace(" ", "")
        
        # é€šè©±æ™‚é–“ã‚’æ•°å€¤åŒ–
        df["é€šè©±æ™‚é–“_num"] = pd.to_numeric(df["é€šè©±æ™‚é–“"], errors="coerce")
        
        # æ–­ã‚Šãƒ»çµ‚äº†ç³»ãƒ¯ãƒ¼ãƒ‰
        ng_words = [
            "æ–­ã‚Š", "ä¸è¦", "å¿…è¦ãªã„", "çµæ§‹ã§ã™", "çµæ§‹",
            "é›»è©±ãŒçµ‚äº†", "é›»è©±ã‚’åˆ‡ã£ãŸ", "åˆ‡æ–­", "å¿œç­”ãªã—", "å¿œç­”ç„¡ã—",
            "åˆ‡ã‚‰ã‚Œ", "åˆ‡ã‚‰ã‚Œã‚‹", "åˆ‡ã£ãŸ", "é€šè©±ãŒçµ‚äº†", "ä¼šè©±ãŒçµ‚äº†",
            "é€²å±•ã—ãªã„", "é€šè©±ã‚’çµ‚äº†", "é€²ã¾ãªã‹ã£ãŸ", "åˆ‡ã‚Šã¾ã—ãŸ", "æ–­å¿µ",
            "çµ‚äº†", "æˆç«‹ã—ãªã‹ã£ãŸ", "åˆ‡", "é€²å±•ã¯ã‚ã‚Šã¾"
        ]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†é¡
        for idx, row in df.iterrows():
            status = str(row["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"])
            result = str(row["æ¶é›»çµæœ"]) if pd.notna(row["æ¶é›»çµæœ"]) else ""
            summary = str(row["è¦ç´„"]) if pd.notna(row["è¦ç´„"]) else ""
            duration = row["é€šè©±æ™‚é–“_num"]
            
            # æ—¢ã«çµæœãŒå…¥ã£ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if result.strip() != "" and result.strip() != "nan":
                continue
            
            # ç•™å®ˆç•ªé›»è©± â†’ ç•™å®ˆé›»
            if status.strip() == "ç•™å®ˆç•ªé›»è©±":
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆé›»"
                continue
            
            # å¿œç­”ãªã— â†’ ç•™å®ˆ
            if status.strip() in ["å¿œç­”ãªã—", "å¿œç­”ç„¡ã—"]:
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # ç²å¾— â†’ AIé›»è©±APO
            if status.strip() == "ç²å¾—":
                df.at[idx, "æ¶é›»çµæœ"] = "AIé›»è©±APO"
                continue
            
            # è¦ç´„ã«æ–­ã‚Šãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ â†’ NG
            if any(word in summary for word in ng_words):
                df.at[idx, "æ¶é›»çµæœ"] = "NG"
                continue
            
            # é€šè©±æ™‚é–“ãŒ0 â†’ ç•™å®ˆ
            if duration == 0:
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒè‡ªå‹•éŸ³å£° â†’ ç•™å®ˆé›»
            if status.strip() == "è‡ªå‹•éŸ³å£°":
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆé›»"
                continue
            
            # è¦ç´„ã«ã€Œå¿œç­”ãªã—ã€ â†’ ç•™å®ˆ
            if any(x in summary for x in ["å¿œç­”ãªã—", "å¿œç­”ç„¡ã—"]):
                df.at[idx, "æ¶é›»çµæœ"] = "ç•™å®ˆ"
                continue
            
            # è¦ç´„ã«ã€Œè»¢é€ã€ã‚„ã€Œäº†æ‰¿ã—ã¾ã—ãŸã€ãªã© â†’ é›»è©±APO
            if any(x in summary for x in ["è»¢é€ã•ã‚ŒãŸ", "äº†æ‰¿ã—ã¾ã—ãŸ", "è»¢é€ã•ã‚Œã¾ã—ãŸ"]):
                df.at[idx, "æ¶é›»çµæœ"] = "AIé›»è©±APO"
                continue
            
            # é€šè©±æ™‚é–“ã‚ã‚Š & è»¢é€ã§ãªã„ â†’ NG
            if pd.notna(duration) and duration > 0 and not any(x in summary for x in ["è»¢é€"]):
                df.at[idx, "æ¶é›»çµæœ"] = "NG"
        
        return df
    
    def merge_with_original(self, call_results_df, job_id):
        """å…ƒãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰"""
        job_dir = self.base_dir / job_id
        
        # ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿
        manifest_path = job_dir / "manifest.json"
        with open(manifest_path, 'r', encoding='utf-8') as f:
            manifest = json.load(f)
        
        # rowmapã‚’èª­ã¿è¾¼ã¿
        rowmap_path = job_dir / "rowmap.csv"
        rowmap_df = pd.read_csv(rowmap_path)
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        original_path = job_dir / "fm_export.xlsx"
        original_df = pd.read_excel(original_path)
        
        # é€šè©±çµæœã®ç¤¾åã‚’æ­£è¦åŒ–
        call_results_df['ç¤¾å_æ­£è¦åŒ–'] = call_results_df['ç¤¾å'].apply(self.normalize_text)
        
        # ç¤¾åãƒ™ãƒ¼ã‚¹ã§ãƒãƒ¼ã‚¸
        merged_df = pd.merge(
            call_results_df, 
            rowmap_df[['company_normalized', 'fm_id', 'company']], 
            left_on='ç¤¾å_æ­£è¦åŒ–', 
            right_on='company_normalized', 
            how='left'
        )
        
        # å…ƒãƒ‡ãƒ¼ã‚¿ã®ä»–ã®åˆ—ã‚‚çµåˆï¼ˆIDã‚’ã‚­ãƒ¼ã«ï¼‰
        if 'fm_id' in merged_df.columns and 'IDã®é ­ã«ID' in original_df.columns:
            # FileMakerã®IDã§ã•ã‚‰ã«è©³ç´°æƒ…å ±ã‚’çµåˆ
            original_subset = original_df[['IDã®é ­ã«ID', 'ä½æ‰€çµ±åˆ', 'æœ€çµ‚ãƒˆãƒ¼ã‚¯åˆ¤å®š', 'æœ€çµ‚æœ‰åŠ¹ç„¡åŠ¹', 'æœ€çµ‚æ±ºæ¸ˆæ‹…å½“']].copy()
            original_subset = original_subset.rename(columns={'IDã®é ­ã«ID': 'fm_id'})
            merged_df = pd.merge(merged_df, original_subset, on='fm_id', how='left')
        
        # é€šè©±çµæœã«è¡ŒæŒ‡ç´‹ã‚’è¿½åŠ 
        merged_df['row_key'] = merged_df.apply(
            lambda row: self.create_row_key(row.get('ç¤¾å', ''), row.get('é›»è©±ç•ªå·', '')), 
            axis=1
        )
        
        # åˆ—ã®é †åºã‚’æ•´ç†
        column_order = ['fm_id', 'ç¤¾å', 'é›»è©±ç•ªå·', 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'æ¶é›»çµæœ', 'è¦ç´„', 'é€šè©±æ™‚é–“', 
                       'ä½æ‰€çµ±åˆ', 'æœ€çµ‚ãƒˆãƒ¼ã‚¯åˆ¤å®š', 'æœ€çµ‚æœ‰åŠ¹ç„¡åŠ¹', 'æœ€çµ‚æ±ºæ¸ˆæ‹…å½“', 'row_key']
        
        # å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’é¸æŠ
        available_columns = [col for col in column_order if col in merged_df.columns]
        merged_df = merged_df[available_columns]
        
        return merged_df
    
    def calculate_statistics(self, df):
        """çµ±è¨ˆã‚’è¨ˆç®—"""
        def parse_duration(val):
            if pd.isna(val):
                return 0
            val = str(val).strip()
            if val in ["", "-", "nan"]:
                return 0
            parts = val.split(":")
            try:
                if len(parts) == 3:  # hh:mm:ss
                    h, m, s = map(int, parts)
                    return h*3600 + m*60 + s
                elif len(parts) == 2:  # mm:ss
                    m, s = map(int, parts)
                    return m*60 + s
                else:
                    return int(val)  # ç§’æ•°
            except:
                return 0
        
        # é€šè©±æ™‚é–“ã‚’ç§’ã«å¤‰æ›
        df["é€šè©±æ™‚é–“_sec"] = df["é€šè©±æ™‚é–“"].apply(parse_duration)
        
        # çµ±è¨ˆè¨ˆç®—
        total_calls = len(df)
        result_counts = df["æ¶é›»çµæœ"].value_counts()
        valid_calls = df[~df["æ¶é›»çµæœ"].isin(["ç•™å®ˆ", "ç•™å®ˆç•ªé›»è©±"])].shape[0]
        total_time_sec = int(df["é€šè©±æ™‚é–“_sec"].sum())
        total_time_str = str(timedelta(seconds=total_time_sec))
        transfer_calls = df[df["æ¶é›»çµæœ"].str.contains("APO", na=False)].shape[0]
        
        # ç„¡åŠ¹ç•ªå·
        df["é›»è©±ç•ªå·_str"] = df["é›»è©±ç•ªå·"].astype(str).str.replace(r"\D", "", regex=True)
        invalid_numbers = df[~df["é›»è©±ç•ªå·_str"].str.match(r"^0\d{9,10}$", na=False)].shape[0]
        
        # ã‚¨ãƒ©ãƒ¼ä»¶æ•°
        error_calls = df[df[["ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "è¦ç´„"]].astype(str).apply(
            lambda x: any("ã‚¨ãƒ©ãƒ¼" in v for v in x), axis=1
        )].shape[0]
        
        return {
            'total_calls': total_calls,
            'valid_calls': valid_calls,
            'total_time': total_time_str,
            'transfer_calls': transfer_calls,
            'invalid_numbers': invalid_numbers,
            'error_calls': error_calls,
            'result_counts': result_counts.to_dict()
        }

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    st.markdown('<h1 class="main-header">ğŸ“ AIãƒ†ãƒ¬ã‚¢ãƒç®¡ç†ã‚·ã‚¹ãƒ†ãƒ </h1>', unsafe_allow_html=True)
    
    manager = AITeleapoManager()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("ğŸ›ï¸ æ“ä½œãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    menu = st.sidebar.selectbox(
        "æ©Ÿèƒ½ã‚’é¸æŠ",
        ["ğŸ“¤ æ–°è¦ã‚¸ãƒ§ãƒ–ä½œæˆ", "ğŸ“¥ çµæœåˆ†æ", "ğŸ“Š ã‚¸ãƒ§ãƒ–å±¥æ­´", "âš™ï¸ è¨­å®š"]
    )
    
    if menu == "ğŸ“¤ æ–°è¦ã‚¸ãƒ§ãƒ–ä½œæˆ":
        st.header("ğŸ“¤ æ–°è¦ã‚¸ãƒ§ãƒ–ä½œæˆ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“ FileMakerãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
            uploaded_file = st.file_uploader(
                "Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
                type=['xlsx', 'xls'],
                help="FileMakerã‹ã‚‰å‡ºåŠ›ã—ãŸExcelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
            )
            
            if uploaded_file:
                try:
                    df = pd.read_excel(uploaded_file)
                    st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {uploaded_file.name}")
                    st.info(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df)} ä»¶")
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                        st.dataframe(df.head(10))
                    
                    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®æŒ‡å®š
                    st.subheader("ğŸ“ å‡ºåŠ›è¨­å®š")
                    output_name = st.text_input(
                        "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                        value="AIãƒ†ãƒ¬ã‚¢ãƒç”¨ãƒªã‚¹ãƒˆ",
                        help="AIãƒ†ãƒ¬ã‚¢ãƒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰"
                    )
                    
                    # ãƒ­ãƒœãƒƒãƒˆå°æ•°é¸æŠ
                    robot_count = st.selectbox(
                        "ğŸ¤– ä½¿ç”¨ã™ã‚‹ãƒ­ãƒœãƒƒãƒˆå°æ•°",
                        [1, 2, 3, 4, 5],
                        index=0,
                        help="åŒæ™‚ã«ä½¿ç”¨ã™ã‚‹AIãƒ†ãƒ¬ã‚¢ãƒãƒ­ãƒœãƒƒãƒˆã®å°æ•°"
                    )
                    
                    if st.button("ğŸš€ ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ", type="primary"):
                        with st.spinner("ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆä¸­..."):
                            job_id = manager.generate_job_id()
                            result = manager.process_filemaker_data(df, job_id, output_name)
                            
                            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                            job_info = {
                                'job_id': job_id,
                                'created_at': datetime.now(),
                                'filename': uploaded_file.name,
                                'output_name': output_name,
                                'robot_count': robot_count,
                                'total_rows': result['total_rows'],
                                'status': 'created'
                            }
                            st.session_state.jobs.append(job_info)
                            
                            st.markdown(f"""
                            <div class="success-box">
                                <h4>âœ… ã‚¸ãƒ§ãƒ–ä½œæˆå®Œäº†</h4>
                                <p><strong>ã‚¸ãƒ§ãƒ–ID:</strong> {job_id}</p>
                                <p><strong>å‡¦ç†ä»¶æ•°:</strong> {result['total_rows']} ä»¶</p>
                                <p><strong>ãƒ­ãƒœãƒƒãƒˆå°æ•°:</strong> {robot_count} å°</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            with open(result['upload_path'], 'rb') as f:
                                st.download_button(
                                    label="ğŸ“¥ AIãƒ†ãƒ¬ã‚¢ãƒç”¨CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    data=f.read(),
                                    file_name=f"{output_name}_{job_id}.csv",
                                    mime="text/csv",
                                    help="æ—¥æœ¬èªå¯¾å¿œã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™"
                                )
                
                except Exception as e:
                    st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with col2:
            st.subheader("ğŸ“‹ å‡¦ç†ã®æµã‚Œ")
            st.markdown("""
            1. **ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
               - FileMakerã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
            
            2. **âš™ï¸ è¨­å®š**
               - å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š
               - ãƒ­ãƒœãƒƒãƒˆå°æ•°ã‚’é¸æŠ
            
            3. **ğŸš€ ã‚¸ãƒ§ãƒ–ä½œæˆ**
               - ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ãƒ»ä¿å­˜
               - ç¤¾åãƒ™ãƒ¼ã‚¹ã®è¡ŒæŒ‡ç´‹ã‚’ç”Ÿæˆ
            
            4. **ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**
               - AIãƒ†ãƒ¬ã‚¢ãƒç”¨CSVã‚’å–å¾—
               - ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            """)
    
    elif menu == "ğŸ“¥ çµæœåˆ†æ":
        st.header("ğŸ“¥ çµæœåˆ†æ")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“Š é€šè©±çµæœã®åˆ†æ")
            
            # ã‚¸ãƒ§ãƒ–é¸æŠ
            if st.session_state.jobs:
                job_options = [f"{job['job_id']} - {job['output_name']}" for job in st.session_state.jobs]
                selected_job_str = st.selectbox("åˆ†æå¯¾è±¡ã®ã‚¸ãƒ§ãƒ–ã‚’é¸æŠ", job_options)
                selected_job_id = selected_job_str.split(" - ")[0]
            else:
                st.warning("âš ï¸ ä½œæˆã•ã‚ŒãŸã‚¸ãƒ§ãƒ–ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã¾ãšæ–°è¦ã‚¸ãƒ§ãƒ–ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
                selected_job_id = None
            
            # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            results_file = st.file_uploader(
                "AIãƒ†ãƒ¬ã‚¢ãƒã®çµæœCSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
                type=['csv'],
                help="AIãƒ†ãƒ¬ã‚¢ãƒã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸé€šè©±çµæœCSVãƒ•ã‚¡ã‚¤ãƒ«"
            )
            
            if results_file and selected_job_id:
                try:
                    results_df = pd.read_csv(results_file)
                    st.success(f"âœ… çµæœãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {results_file.name}")
                    st.info(f"ğŸ“Š é€šè©±ä»¶æ•°: {len(results_df)} ä»¶")
                    
                    # çµæœã‚’åˆ†æ
                    analyzed_df = manager.analyze_call_results(results_df)
                    
                    # çµ±è¨ˆã‚’è¨ˆç®—
                    stats = manager.calculate_statistics(analyzed_df)
                    
                    # çµ±è¨ˆè¡¨ç¤º
                    st.subheader("ğŸ“ˆ é€šè©±çµ±è¨ˆ")
                    col_stat1, col_stat2, col_stat3 = st.columns(3)
                    
                    with col_stat1:
                        st.metric("ç·é€šè©±ä»¶æ•°", stats['total_calls'])
                        st.metric("æœ‰åŠ¹é€šè©±ä»¶æ•°", stats['valid_calls'])
                    
                    with col_stat2:
                        st.metric("ç·é€šè©±æ™‚é–“", stats['total_time'])
                        st.metric("è»¢é€ä»¶æ•°", stats['transfer_calls'])
                    
                    with col_stat3:
                        st.metric("ç„¡åŠ¹ç•ªå·", stats['invalid_numbers'])
                        st.metric("ã‚¨ãƒ©ãƒ¼ä»¶æ•°", stats['error_calls'])
                    
                    # çµæœåˆ†å¸ƒ
                    st.subheader("ğŸ“Š æ¶é›»çµæœåˆ†å¸ƒ")
                    result_df = pd.DataFrame(list(stats['result_counts'].items()), 
                                           columns=['çµæœ', 'ä»¶æ•°'])
                    st.dataframe(result_df, use_container_width=True)
                    
                    # å…ƒãƒ‡ãƒ¼ã‚¿ã¨ãƒãƒ¼ã‚¸ï¼ˆç¤¾åãƒ™ãƒ¼ã‚¹ï¼‰
                    merged_df = manager.merge_with_original(analyzed_df, selected_job_id)
                    
                    # ãƒãƒ¼ã‚¸çµæœã®ç¢ºèª
                    st.subheader("ğŸ”— ãƒãƒ¼ã‚¸çµæœ")
                    matched_count = merged_df['fm_id'].notna().sum()
                    st.info(f"ğŸ“Š ãƒãƒƒãƒã—ãŸä»¶æ•°: {matched_count} / {len(merged_df)} ä»¶")
                    
                    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®æŒ‡å®š
                    st.subheader("ğŸ’¾ çµæœä¿å­˜")
                    output_filename = st.text_input(
                        "å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                        value=f"çµæœ_{selected_job_id}",
                        help="FileMakerã«å–ã‚Šè¾¼ã‚€ãŸã‚ã®Excelãƒ•ã‚¡ã‚¤ãƒ«å"
                    )
                    
                    if st.button("ğŸ’¾ çµæœã‚’ä¿å­˜", type="primary"):
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M")
                        final_filename = f"{output_filename}_{timestamp}.xlsx"
                        
                        # ãƒ¡ãƒ¢ãƒªä¸Šã§Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
                        from io import BytesIO
                        buffer = BytesIO()
                        merged_df.to_excel(buffer, index=False, engine='openpyxl')
                        buffer.seek(0)
                        
                        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                        st.download_button(
                            label="ğŸ“¥ åˆ†æçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=buffer.getvalue(),
                            file_name=final_filename,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        
                        st.success(f"âœ… åˆ†æå®Œäº†ï¼ãƒ•ã‚¡ã‚¤ãƒ«: {final_filename}")
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                    with st.expander("ğŸ“‹ åˆ†ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                        st.dataframe(merged_df.head(20))
                
                except Exception as e:
                    st.error(f"âŒ çµæœåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        
        with col2:
            st.subheader("ğŸ“‹ åˆ†æã®æµã‚Œ")
            st.markdown("""
            1. **ğŸ¯ ã‚¸ãƒ§ãƒ–é¸æŠ**
               - åˆ†æå¯¾è±¡ã®ã‚¸ãƒ§ãƒ–ã‚’é¸æŠ
            
            2. **ğŸ“Š çµæœã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**
               - AIãƒ†ãƒ¬ã‚¢ãƒã®çµæœCSVã‚’é¸æŠ
            
            3. **ğŸ” è‡ªå‹•åˆ†æ**
               - é€šè©±çµæœã‚’è‡ªå‹•åˆ¤å®š
               - çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
            
            4. **ğŸ”— ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¸**
               - ç¤¾åãƒ™ãƒ¼ã‚¹ã§å…ƒãƒ‡ãƒ¼ã‚¿ã¨çµåˆ
               - FileMakerç”¨IDã‚’å¾©å…ƒ
            
            5. **ğŸ’¾ çµæœä¿å­˜**
               - Excelãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›
               - FileMakerã«å–ã‚Šè¾¼ã¿å¯èƒ½
            """)
    
    elif menu == "ğŸ“Š ã‚¸ãƒ§ãƒ–å±¥æ­´":
        st.header("ğŸ“Š ã‚¸ãƒ§ãƒ–å±¥æ­´")
        
        if st.session_state.jobs:
            st.subheader("ğŸ“‹ ä½œæˆæ¸ˆã¿ã‚¸ãƒ§ãƒ–ä¸€è¦§")
            
            for job in reversed(st.session_state.jobs):  # æ–°ã—ã„é †ã«è¡¨ç¤º
                with st.expander(f"ğŸ¯ {job['job_id']} - {job['output_name']}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**ä½œæˆæ—¥æ™‚:** {job['created_at'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.write(f"**å…ƒãƒ•ã‚¡ã‚¤ãƒ«:** {job['filename']}")
                        st.write(f"**å‡ºåŠ›å:** {job['output_name']}")
                    with col2:
                        st.write(f"**ãƒ­ãƒœãƒƒãƒˆå°æ•°:** {job['robot_count']} å°")
                        st.write(f"**å‡¦ç†ä»¶æ•°:** {job['total_rows']} ä»¶")
                        st.write(f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** {job['status']}")
        else:
            st.info("ğŸ“ ã¾ã ã‚¸ãƒ§ãƒ–ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    elif menu == "âš™ï¸ è¨­å®š":
        st.header("âš™ï¸ è¨­å®š")
        
        st.subheader("ğŸ—‚ï¸ ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ç®¡ç†")
        
        if st.button("ğŸ—‘ï¸ å…¨ã‚¸ãƒ§ãƒ–å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
            st.session_state.jobs = []
            st.success("âœ… ã‚¸ãƒ§ãƒ–å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
        
        st.subheader("â„¹ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
        st.info(f"""
        **ã‚¸ãƒ§ãƒ–ä¿å­˜å ´æ‰€:** {manager.base_dir.absolute()}
        **ä½œæˆæ¸ˆã¿ã‚¸ãƒ§ãƒ–æ•°:** {len(st.session_state.jobs)}
        **ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** 2.0.0 (ç¤¾åãƒ™ãƒ¼ã‚¹ãƒãƒ¼ã‚¸å¯¾å¿œ)
        """)






if __name__ == "__main__":
    main()
